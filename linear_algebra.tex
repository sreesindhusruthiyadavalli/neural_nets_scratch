\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\begin{document}

\title{Linear Algebra Notes}
\author{}
\date{}
\maketitle

\section{Vector in 2D Space}

$\vec{u} = a\vec{v} + b\vec{w}$ 

$u$ is a linear combination of $v$ and $w$ with scalars $a$ and $b$. $\rightarrow$ $u$ is linearly dependent on $v$ and $w$.

$\vec{u} \neq a\vec{v} + b\vec{w}$ $\rightarrow$ $u$ is not a linear combination of $v$ and $w$ $\rightarrow$ $u$ is linearly independent of $v$ and $w$.

\textbf{Basis vector}: A set of vectors that are linearly independent and span the vector space.
In 2D space, the standard basis vectors are: $\vec{i} = [1, 0]$, $\vec{j} = [0, 1]$

\textbf{Span}: The set of all possible linear combinations of a set of vectors.
In 2D space, the span of $\vec{i}$ and $\vec{j}$ is the entire 2D plane.

\textbf{Linear Transformation}: A function that maps vectors from one vector space to another while preserving vector addition and scalar multiplication.
Linear transformation where base vector shouldn't change and there has to be no curves after transformation

$\vec{v} = -1\hat{i} + 2\hat{j}$ $\rightarrow$ geometric representation of vector $v$ in 2D space

Now there is a transformation where the grids move in some direction but the base vectors remain the same. 
The vector $v$ after transformation becomes:

Transformed $\vec{v} = -1$ transformed $\vec{\hat{i}} + 2$ transformed $\vec{\hat{j}}$

during the transformation, all three vectors move in the same way.

The transformed basis vectors are still orthogonal and have the same length as the original basis vectors.

after transformation, let's say the 
transformed $\vec{\hat{i}} = \begin{bmatrix} 1 \\ -2 \end{bmatrix}$

and transformed $\vec{\hat{j}} = \begin{bmatrix} 3 \\ 1 \end{bmatrix}$

Then the transformed vector $v$ becomes:       
Transformed $\vec{v} = -1 \begin{bmatrix} 1 \\ -2 \end{bmatrix} + 2 \begin{bmatrix} 3 \\ 1 \end{bmatrix}$     
                                         
$= \begin{bmatrix} -1(1) + 2(3) \\ -1(-2) + 2(1) \end{bmatrix}$
      
$= \begin{bmatrix} 5 \\ 4 \end{bmatrix}$      

The transformation is basically where $\vec{\hat{i}}$ and $\vec{\hat{j}}$ lands after transformation. 

The same transformed $\vec{\hat{i}}$ and transformed $\vec{\hat{j}}$ can also be represented as $2 \times 2$ grid(matrix):
$$\begin{bmatrix} 1 & 3 \\ -2 & 1 \end{bmatrix}$$

the first column is transformed $\vec{\hat{i}}$ and the second column is transformed $\vec{\hat{j}}$.

Now for any given vector $\vec{v} = x\vec{\hat{i}} + y\vec{\hat{j}}$, the transformed vector can be calculated as:
Transformed $\vec{v} = \vec{v} \times \begin{bmatrix} 1 & 3 \\ -2 & 1 \end{bmatrix}$

\textbf{Composition of two linear transformations}: Applying two linear transformations in succession is equivalent to multiplying their corresponding matrices.                                        
If we have two transformations represented by matrices $A$ and $B$, then applying transformation $A$ followed by transformation $B$ is equivalent to multiplying the matrices:

Transformed $\vec{v} = \vec{v} \times$ first transformation matrix $A \times$ second transformation matrix $B$

This property allows us to combine multiple linear transformations into a single transformation matrix by multiplying the individual matrices together.

the order of transformation will land the $\vec{\hat{i}}$ and $\vec{\hat{j}}$ in different positions. 
So order of the transformation matters. it is not commutative but associative.

Refer img1 in linear\_alg.md for 3d representation.

\textbf{Determinant of a transformation}:

After transformation,

In 2d space: the area of the shape formed by the transformed basis vectors($\vec{\hat{i}}, \vec{\hat{j}}$) is given by the 
absolute value of the determinant of the transformation matrix. 

In other words, the determinant tells us how much the area has been scaled during the transformation.

In 3d space: the volume of the shape formed by the transformed basis vectors($\vec{\hat{i}}, \vec{\hat{j}}, \vec{\hat{k}}$) is given by the absolute value of the determinant of the transformation matrix.

If the transformation results in a negative determinant, it indicates that the orientation of the basis vectors has been reversed (e.g., a reflection).

$\det(M_1M_2) = \det(M_1) \times \det(M_2)$

This property shows that the overall scaling effect of two successive transformations is the product of their individual scaling effects.

\end{document}